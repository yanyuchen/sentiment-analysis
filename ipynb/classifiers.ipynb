{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNx7z2ZCmN3z"
   },
   "source": [
    "# Using NLTK’s built-in classifiers for Sentiment Analyzer\n",
    "NLTK also offers a few built-in classifiers that are suitable for various types of analyses, including sentiment analysis. The trick is to figure out which properties of our dataset are useful in classifying each piece of data into our desired categories. Let's start it as a warm up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIuNDSr2nKhb"
   },
   "source": [
    "## Loading Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7rvMQf4vnJvd",
    "outputId": "1408c489-66c7-43d4-9768-227f993d6e77"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/yanyuchen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/yanyuchen/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/yanyuchen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from random import shuffle\n",
    "import random\n",
    "from nltk.tokenize import word_tokenize \n",
    "import numpy as np\n",
    "\n",
    "nltk.download([\"stopwords\", \"vader_lexicon\", \"punkt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "Ubaf_2kvnWDp",
    "outputId": "02a919e4-a7d4-4b55-eb40-a22adfb19f22"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My family took the tour ( BUY TICKETS IN ADVAN...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a must stop if you are in San Fran!!! ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I did not expect to enjoy the tour as much as ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>San Francisco is completely unsafe. We bought ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I had a 13-hour layover in San Francisco And I...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating\n",
       "0  My family took the tour ( BUY TICKETS IN ADVAN...     5.0\n",
       "1  This is a must stop if you are in San Fran!!! ...     5.0\n",
       "2  I did not expect to enjoy the tour as much as ...     5.0\n",
       "3  San Francisco is completely unsafe. We bought ...     1.0\n",
       "4  I had a 13-hour layover in San Francisco And I...     4.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/yanyuchen/sentiment-analysis/main/data/all_reviews.csv'\n",
    "df = pd.read_csv(url)[['review', 'rating']].dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTauDeBFnuns"
   },
   "source": [
    "## Training and Using a Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-ZRyGaeqYez"
   },
   "source": [
    "The common words in NLP, called the stop words, may have a negative effect on our analysis because they occur so often in the text. We drop them when we fit our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "urBuzOHGougY"
   },
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "stopwords.update(nltk.corpus.stopwords.words(\"spanish\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NYm048Bxn6jX"
   },
   "outputs": [],
   "source": [
    "act = df.rating > 3\n",
    "features = [(df.review[i], act[i]) for i in range(len(act))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiyTwhHLrfyr"
   },
   "source": [
    "Training the classifier involves random splitting the feature set so that one portion can be used for training and the other for evaluation. For the purpose of reproducibility, we fix our random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UHmCESP3rxqh"
   },
   "outputs": [],
   "source": [
    "random.seed(220)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLvU3KnyrAkL"
   },
   "source": [
    "We split the string of review into several peices of words and use the words that are not in the stop words list to fit our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "YuuIq3WbohOz"
   },
   "outputs": [],
   "source": [
    "train_count = round(len(features) * 0.8)\n",
    "shuffle(features)\n",
    "train = features[:train_count]\n",
    "all_words = set(word.lower() for passage in train for word in word_tokenize(passage[0]) if word.lower() not in stopwords)\n",
    "#t = [({word: (word in word_tokenize(x[0])) for word in all_words}, x[1]) for x in train]\n",
    "# speed up:\n",
    "t = [({word: False for word in all_words} | {word: True for word in word_tokenize(passage[0]) if word.lower() not in stopwords},\n",
    "      label) for passage, label in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AJGKy2sSoiwB",
    "outputId": "ca3f5431-f34e-46f3-a426-ae065be8f6b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                       9 = True            False : True   =     11.0 : 1.0\n",
      "                       $ = True            False : True   =      6.6 : 1.0\n",
      "                       4 = True            False : True   =      6.6 : 1.0\n",
      "                       8 = True            False : True   =      6.6 : 1.0\n",
      "                      `` = True            False : True   =      6.6 : 1.0\n",
      "                       Н = True            False : True   =      6.6 : 1.0\n",
      "                       ア = True            False : True   =      6.6 : 1.0\n",
      "                       子 = True            False : True   =      6.6 : 1.0\n",
      "                       전 = True            False : True   =      6.6 : 1.0\n",
      "                       È = True            False : True   =      4.7 : 1.0\n",
      "                       c = True            False : True   =      4.0 : 1.0\n",
      "                       Е = True            False : True   =      4.0 : 1.0\n",
      "                       П = True            False : True   =      4.0 : 1.0\n",
      "                       샌 = True            False : True   =      3.7 : 1.0\n",
      "                       v = True            False : True   =      3.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(t)\n",
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Dapy_fVGYiH",
    "outputId": "7bd2c3ae-b9d5-4e5b-cc00-3f0944c35c7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8696296296296296"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3rzud5eVXhG"
   },
   "source": [
    "The result shows that our fitted model performs better than the previous naive approach on the training set. However, it is unclear why we obtain those words to be our most informative features. Next, let's see its performance on the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZWDq-3BQbu-"
   },
   "source": [
    "## Evaluating on the Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Racz98VoFTt2"
   },
   "outputs": [],
   "source": [
    "test = features[train_count:]\n",
    "s = [{word: False for word in all_words} | {word: True for word in word_tokenize(passage[0]) if word.lower() not in stopwords}\n",
    "     for passage, _ in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "jg7xY9MFW2q9"
   },
   "outputs": [],
   "source": [
    "pred = classifier.classify_many(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "AT7vXs1TNekD"
   },
   "outputs": [],
   "source": [
    "def accuracy(pred, act):\n",
    "    return sum([pred[i] == act[i] for i in range(len(act))])/len(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "7-Ufel-pQpkF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act = [ts[1] for ts in test]\n",
    "\n",
    "accuracy(pred, act)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance on the testing set is similar to that on the training set. It indicates no overfitting happened and suggests its ability of the generalization also outperforms the naive approach. Before we end this section, let's make a prediction on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = [review for review in df.review] # preserve the order\n",
    "all_w = [{word: False for word in all_words} | {word: True for word in word_tokenize(passage) if word.lower() not in stopwords}\n",
    "     for passage in review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all = classifier.classify_many(all_w)\n",
    "pd.DataFrame(pred_all).to_csv('NaiveBayesClassifier_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EByRpc1umjLv"
   },
   "source": [
    "# Comparing Additional Classifiers with Scikit-learn\n",
    "NLTK provides a class that can use most classifiers from the popular machine learning framework, scikit-learn. Many of the classifiers that scikit-learn provides can be instantiated quickly since they have defaults that often work well. Since NLTK allows us to integrate scikit-learn classifiers directly into its own classifier class, the training and classification processes will use the same methods we’ve already seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "LoV9vXpyRbtJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import (BernoulliNB, ComplementNB, MultinomialNB,)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "uY4F-sMZRAEv"
   },
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"BernoulliNB\": BernoulliNB(),\n",
    "    \"ComplementNB\": ComplementNB(),\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    \"MLPClassifier\": MLPClassifier(max_iter=1000),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "q5p5X74-RPE2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB finish\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "pred_list = []\n",
    "\n",
    "for name, sklearn_classifier in classifiers.items():\n",
    "    classifier = nltk.classify.SklearnClassifier(sklearn_classifier)\n",
    "    classifier.train(t)\n",
    "    \n",
    "    # training set\n",
    "    accur = nltk.classify.accuracy(classifier, t)\n",
    "    accuracy_list.append(accur)\n",
    "    \n",
    "    # testing set\n",
    "    pred = classifier.classify_many(s)\n",
    "    pred_list.append(accuracy(pred, act))\n",
    "    \n",
    "    # whole dataset\n",
    "    pred_all = classifier.classify_many(all_w)\n",
    "    pd.DataFrame(pred_all).to_csv('NaiveBayesClassifier_pred.csv', index=False)\n",
    "    \n",
    "    print(F\"{name} finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BernoulliNB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.868418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          BernoulliNB\n",
       "accuracy     0.868418"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(accuracy_list, columns = list(classifiers.keys()), index = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       My family took the tour ( BUY TICKETS IN ADVAN...\n",
       "1       This is a must stop if you are in San Fran!!! ...\n",
       "2       I did not expect to enjoy the tour as much as ...\n",
       "3       San Francisco is completely unsafe. We bought ...\n",
       "4       I had a 13-hour layover in San Francisco And I...\n",
       "                              ...                        \n",
       "9276    It has now been several years since the big re...\n",
       "9277    Nothing screams San Francisco like Mission Dol...\n",
       "9278    I think this might be one of my new absolute f...\n",
       "9279    It was my second time here . \\nThe young gentl...\n",
       "9280    IMO. Dundundun.. \\n\\nGuava & Coconut = Delicio...\n",
       "Name: review, Length: 9281, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on the Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BernoulliNB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          BernoulliNB\n",
       "accuracy        0.875"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pred_list, columns = list(classifiers.keys()), index = ['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
