{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sources\n",
    "\n",
    "**Content**\n",
    "1. TripAdvisor Web Scraping\n",
    "2. Yelp API\n",
    "3. Google Reviews"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. TripAdvisor Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"/Users/alliewu/Desktop/DataScience_Projects/SF_Top_Attractions/chromedriver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_review(name):\n",
    "    username, city, country, contribution, title, month, year, review, ratings = [],[],[],[],[],[],[],[],[]\n",
    "    for i in range(1,26):\n",
    "        review_chuncks = driver.find_element(By.CLASS_NAME, 'LbPSX')\n",
    "        \n",
    "        chunck_list = review_chuncks.text.split('\\nThis review is the subjective opinion of a Tripadvisor member and not of Tripadvisor LLC. Tripadvisor performs checks on reviews.\\n')\n",
    "        chunck_list.pop(-1)\n",
    "\n",
    "        for chunck in chunck_list:\n",
    "            try:\n",
    "                review_element = chunck.split('\\n')\n",
    "\n",
    "                # element 1: username\n",
    "                username.append(review_element[0].strip())\n",
    "                \n",
    "                # element 2,3,4:  city, country, contribution\n",
    "                mix_string = review_element[1]\n",
    "                pattern = r'([\\w\\s]+),\\s*([\\w\\s]+)\\s*(\\d+)\\s*contributions'\n",
    "                match = re.match(pattern, mix_string)\n",
    "                if match:\n",
    "                    city.append(match.group(1))\n",
    "                    country.append(match.group(2))\n",
    "                    contribution.append(match.group(3))\n",
    "                else:\n",
    "                    city.append('None')\n",
    "                    country.append('None')\n",
    "                    contribution.append(review_element[1].replace('contributions','').strip())\n",
    "                \n",
    "                # element 5: title\n",
    "                title.append(review_element[3].strip())\n",
    "                \n",
    "                # element 6,7: month, year\n",
    "                element4 = review_element[4].split(' â€¢ ')[0]\n",
    "                if len(element4.split()) >= 2:\n",
    "                    month.append(element4.split()[0])\n",
    "                    year.append(element4.split()[1])\n",
    "                else:\n",
    "                    month.append('None')\n",
    "                    year.append('None')\n",
    "                \n",
    "                # element 8: review\n",
    "                review.append(review_element[5].strip())\n",
    "            \n",
    "            except IndexError:\n",
    "                continue\n",
    "        \n",
    "        # element 9: rating\n",
    "        rating_elements = review_chuncks.find_elements(By.CLASS_NAME, 'UctUV.d.H0')\n",
    "        for i in range(len(rating_elements)):\n",
    "            try:\n",
    "                rating_string = rating_elements[i].get_attribute(\"aria-label\")\n",
    "                rating = rating_string.split()[0]\n",
    "                ratings.append(rating)\n",
    "            except IndexError:\n",
    "                continue\n",
    "                \n",
    "        driver.find_element(By.XPATH, '//*[@id=\"tab-data-qa-reviews-0\"]/div/div[5]/div/div[11]/div[1]/div/div[1]/div[2]/div/a').click()\n",
    "        time.sleep(3)\n",
    "\n",
    "    attraction = [name]*len(username)\n",
    "    review_dict = {'attraction':attraction,\n",
    "                'username':username,\n",
    "                'city': city,\n",
    "                'country': country,\n",
    "                'contribution': contribution,\n",
    "                'title': title,\n",
    "                'month': month,\n",
    "                'year': year,\n",
    "                'review': review,\n",
    "                'rating': ratings}\n",
    "    review = pd.DataFrame(review_dict)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place = pd.read_csv('SF_places.csv')\n",
    "place_rating = []\n",
    "all_reviews = pd.DataFrame(columns=['attraction', 'username', 'city', 'country', \n",
    "                           'contribution', 'title', 'month', 'year', 'review', 'rating'])\n",
    "for i in range(place.shape[0]): #place.shape[0]\n",
    "    try:\n",
    "        url = place['url'][i]\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(5)\n",
    "        driver.execute_script(\"window.scrollBy(0, 2000);\")\n",
    "        time.sleep(10)\n",
    "\n",
    "        language_button = '//*[@id=\"tab-data-qa-reviews-0\"]/div/div[1]/div/div/div[2]/div/div/div[2]/div/div/div/button'\n",
    "        all_language_button = '//*[@id=\"menu-item-all\"]'\n",
    "        driver.find_element(By.XPATH, language_button).click()\n",
    "        time.sleep(5)\n",
    "        driver.find_element(By.XPATH, all_language_button).click()\n",
    "        time.sleep(5)\n",
    "\n",
    "        place_rating.append(driver.find_element(By.CLASS_NAME, 'biGQs._P.fiohW.hzzSG.uuBRH').text)\n",
    "        \n",
    "        name = place['name'][i]\n",
    "        reviews = scrape_review(name=name)\n",
    "        \n",
    "        all_reviews = pd.concat([all_reviews, reviews])\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing row {i}: {e}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Yelp API\n",
    "- Document API: https://docs.developer.yelp.com/docs/fusion-intro\n",
    "- We get two dataframes: businesses around SF; reviews to all businesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can only get n_review <= 3, n_business <= 50, review text with certain pieces\n",
    "\n",
    "def get_yelp(key, loc = \"San Francisco, CA\", t_sleep = 0.1, n_business = 50, n_review = 3):\n",
    "    headers = {\"Authorization\": \"Bearer %s\" % key}\n",
    "    url = \"https://api.yelp.com/v3/businesses/search\"\n",
    "    params={\"limit\": n_business, \"location\": loc}\n",
    "    response = requests.get(url, headers=headers, params=params) #The API does not return businesses without any reviews\n",
    "    businesses = response.json()[\"businesses\"]\n",
    "    businesses_pd = pd.DataFrame([business for business in businesses])\n",
    "    appended_data = [None] * n_business\n",
    "    i = 0\n",
    "    for business in businesses:\n",
    "        url2 = \"https://api.yelp.com/v3/businesses/\" + business['id'] + '/reviews'\n",
    "        params2={\"limit\": n_review, \"sort_by\": \"newest\"}\n",
    "        time.sleep(t_sleep)\n",
    "        response2 = requests.get(url2, headers=headers, params=params2)\n",
    "        reviews = response2.json()[\"reviews\"]\n",
    "        reviews_pd = pd.DataFrame([review for review in reviews])\n",
    "        reviews_pd['business_id'] = business['id']\n",
    "        appended_data[i] = reviews_pd\n",
    "        i += 1\n",
    "    return [businesses_pd, pd.concat(appended_data, ignore_index=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"scWgvjtjmz1UMUb9LD1q6C8qDEZkOrNjv6ZVrf9jFU4GurLk9QlA8CC3-Ac1GWEAUEvG7weRAOp-Uo1ay-kMtOPLsM7UFlY4FDlpurtYwrVPNen-j9WMsjHw7o4ZZHYx\"\n",
    "businesses, reviews = get_yelp(key = api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "businesses.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Google Reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place = pd.read_csv('SF_places.csv')\n",
    "csv_name = !ls new_google_review\n",
    "csv_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data = pd.read_csv(f'/Users/alliewu/Desktop/DataScience_Projects/SF_Top_Attractions/new_google_review/{filename}')\n",
    "    \n",
    "    # Remove the prefix before the underscore\n",
    "    filename = filename.split('_', 1)[1]\n",
    "\n",
    "    # Remove the suffix after the dot\n",
    "    filename = filename.rsplit('.', 1)[0]\n",
    "\n",
    "    # Replace underscores with spaces\n",
    "    filename = filename.replace('_', ' ')\n",
    "    data['attraction'] = [filename]*(data.shape[0])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data('google_Adventure_Playground.csv')\n",
    "for i in range(1,len(csv_name)): #place.shape[0]\n",
    "    filename = csv_name[i]\n",
    "    #name = place['name'][i]\n",
    "    reviews = load_data(filename=filename)\n",
    "    data = pd.merge(data, reviews, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={'d4r55': 'username', \n",
    "                            'RfnDt 2': 'contributions',\n",
    "                            'rsqaWe': 'time',\n",
    "                            'wiI7pd': 'review',\n",
    "                            'kyuRq 2': 'language'\n",
    "                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hCCjke src'] = [1]*data.shape[0]\n",
    "    \n",
    "data['hCCjke src 2'] = data['hCCjke src 2'].replace({'https://maps.gstatic.com/consumer/images/icons/2x/ic_star_rate_14.png': 1, \n",
    "                                                 'https://maps.gstatic.com/consumer/images/icons/2x/ic_star_rate_empty_14.png': 0})\n",
    "data['hCCjke src 3'] = data['hCCjke src 3'].replace({'https://maps.gstatic.com/consumer/images/icons/2x/ic_star_rate_14.png': 1, \n",
    "                                                 'https://maps.gstatic.com/consumer/images/icons/2x/ic_star_rate_empty_14.png': 0})\n",
    "data['hCCjke src 4'] = data['hCCjke src 4'].replace({'https://maps.gstatic.com/consumer/images/icons/2x/ic_star_rate_14.png': 1, \n",
    "                                                 'https://maps.gstatic.com/consumer/images/icons/2x/ic_star_rate_empty_14.png': 0})\n",
    "data['hCCjke src 5'] = data['hCCjke src 5'].replace({'https://maps.gstatic.com/consumer/images/icons/2x/ic_star_rate_14.png': 1, \n",
    "                                                 'https://maps.gstatic.com/consumer/images/icons/2x/ic_star_rate_empty_14.png': 0})\n",
    "\n",
    "data['rating'] = data.apply(lambda row: row['hCCjke src'] + row['hCCjke src 2'] + row['hCCjke src 3'] + row['hCCjke src 4']+ row['hCCjke src 5'], axis=1)\n",
    "\n",
    "data['language'] = data['language'].replace(np.nan, 'English')\n",
    "data['contributions'] = [str(i).replace(' reviews','').strip() for i in data['contributions']]\n",
    "data['contributions'] = [i.replace('Â· ','').strip() for i in data['contributions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(date_str):\n",
    "    if isinstance(date_str, str):\n",
    "        if date_str.endswith('ago'):\n",
    "            try:\n",
    "                num = int(date_str.split()[0])\n",
    "            except:\n",
    "                num = 1\n",
    "            if 'day' in date_str:\n",
    "                return (datetime.today() - timedelta(days=num)).strftime('%b %Y')\n",
    "            elif 'week' in date_str:\n",
    "                return (datetime.today() - timedelta(weeks=num)).strftime('%b %Y')\n",
    "            elif 'month' in date_str:\n",
    "                return (datetime.today() - timedelta(days=num*30)).strftime('%b %Y')\n",
    "            elif 'year' in date_str:\n",
    "                return (datetime.today() - timedelta(days=num*365)).strftime('%b %Y')\n",
    "    return np.nan\n",
    "\n",
    "data['time'] = [convert_date(i) for i in data['time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_columns = ['attraction','username','contributions', 'time','review','rating'] #,'language'\n",
    "\n",
    "# Keep only the specified columns\n",
    "google_reviews = data.loc[:, keep_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_reviews.dropna(subset=['review'], inplace=True)\n",
    "google_reviews.head(5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
