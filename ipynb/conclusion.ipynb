{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "Our study aimed to explore the sentiment of users towards various locations by analyzing their reviews on three popular review sites, namely TripAdvisor, Google Maps, and Yelp. To achieve this, we employed a combination of web scraping and API methods to collect the data, and then utilized natural language processing (NLP) techniques to standardize the reviews and find their frequency.\n",
    "\n",
    "We began by collecting reviews of different locations from the three review sites mentioned above. This allowed us to obtain a diverse dataset containing a wide range of reviews, including positive and negative ones. We then used NLP techniques to preprocess the data and extract useful information from the reviews.\n",
    "\n",
    "One of the first things we observed during our analysis was that certain words were frequently used across all rating levels. These included words like \"place,\" \"great,\" \"museum,\" and \"San Francisco.\" This indicates that users tend to describe the general characteristics of a location in their reviews, regardless of whether they had a positive or negative experience.\n",
    "\n",
    "However, we also noticed that reviews with lower ratings tended to mention negative aspects related to visiting with children. This suggests that some locations may not be suitable for families with kids or may not offer sufficient facilities for them. This information can be valuable for businesses in the tourism industry to improve their services and cater to the needs of families.\n",
    "\n",
    "To perform sentiment analysis on our dataset, we compared the performance of various classifiers, including NLTK's VADER and NaiveBayesClassifier, as well as scikit-learn's BernoulliNB, ComplementNB, MultinomialNB, DecisionTreeClassifier, LogisticRegression, and RandomForestClassifier. We evaluated the accuracy, compatibility with other classifiers, and time efficiency of each classifier to determine the best option for our dataset.\n",
    "\n",
    "Our results showed that all scikit-learn classifiers performed similarly in terms of accuracy. However, DecisionTreeClassifier was the best option overall due to its compatibility with other classifiers and time efficiency. This classifier is easy to interpret and can be useful for predicting the sentiment of reviews in real-time applications.\n",
    "\n",
    "Overall, our study highlights the importance of analyzing reviews from multiple sources and using NLP techniques for sentiment analysis. This can provide valuable insights to businesses in the tourism industry, helping them to gain a better understanding of their customers and make more informed decisions. In conclusion, our findings can be used to improve services and cater to the needs of customers in the tourism industry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################  Overall Statistics ####################### \n",
    "# examine data\n",
    "review_all.info()\n",
    "\n",
    "We firstly examined the data `review_all`, and it shows that there are some null values in the *review* column, and the *datecolumn* are not in the correct data type. We therefore converted the *datecolumn* and dropped empty rows based on *reviews*, and then drop duplicates from the data.\n",
    "\n",
    "# Convert the 'date' column to datetime format\n",
    "review_all['datecolumn'] = pd.to_datetime(review_all['datecolumn'], format='%b, %Y')\n",
    "\n",
    "# Drop rows with null values in the 'review' column\n",
    "review_all = review_all.dropna(subset=['review'])\n",
    "\n",
    "# Drop duplicate\n",
    "review_all = review_all.drop_duplicates()\n",
    "review_all.info()\n",
    "\n",
    "And then we examined the numbers of platform, attraction and reviews.\n",
    "\n",
    "# Examined the numbers of platform, attraction and reviews\n",
    "platforms = review_all['platform'].unique()\n",
    "places = review_all['attraction'].unique()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Indicator(\n",
    "    mode = \"number\",\n",
    "    value = len(platforms),\n",
    "    title = {'text': \"Platforms\",'font': {'color': 'black','size':20}},\n",
    "    number={'font':{'color': 'black','size':50}},\n",
    "    domain = {'row': 0, 'column': 0}\n",
    "))\n",
    "fig.add_trace(go.Indicator(\n",
    "    mode = \"number\",\n",
    "    value = len(places),\n",
    "    title = {'text': \"Attractions\",'font': {'color': 'brown','size':20}},\n",
    "    number={'font':{'color': 'brown','size':50}},\n",
    "    domain = {'row': 0, 'column': 1}\n",
    "))\n",
    "fig.add_trace(go.Indicator(\n",
    "    mode = \"number\",\n",
    "    value = len(review_all['review']),\n",
    "    title = {'text': \"Reviews\",'font': {'color': 'green','size':20}},\n",
    "    number={'font':{'color': 'green','size':50}},\n",
    "    domain = {'row': 0, 'column': 2}\n",
    "))\n",
    "fig.update_layout(\n",
    "    grid = {'rows': 1, 'columns': 3, 'pattern': \"independent\"})\n",
    "fig.show()\n",
    "\n",
    "###################  Platform Wise Analysis ######################## \n",
    "We analyzed the distribution of where reviews are coming from, and then analyze what attractions are in obtained in our data and their shares to each platform.\n",
    "\n",
    "# Create pie chart\n",
    "fig1 = px.pie(review_all, names='platform')\n",
    "fig1.update_layout(title='Pie Charts of Platform')\n",
    "fig1.show()\n",
    "\n",
    "It shows that most of our reviews are coming from TripAdvisor and only a little percent are from Yelp. This happens because Yelp API has limitation of only 3 reviews available for each location, while TripAdvisor and Google don't have.\n",
    "\n",
    "# Create a function to make pie charts with specific platform\n",
    "def platform_piechart(platform, column):\n",
    "    t_place_count = review_all.loc[review_all['platform']==platform][column].value_counts().sort_values()\n",
    "    fig = px.pie(t_place_count, \n",
    "             values=column, \n",
    "             names=t_place_count.index,\n",
    "             title = f'{column}s from {platform} ')\n",
    "    fig.show()\n",
    "\n",
    "# Print three piechart with respect to piechart\n",
    "for platform in platforms:\n",
    "    platform_piechart(platform,'attraction')\n",
    "\n",
    "Above plots shows what places are included in the data. We can see most of the places got from yelp are restaurants rather than attractions.\n",
    "\n",
    "########################  Attraction Wise Analysis ########################  \n",
    "Here we focus on the number of reviews we obtained for different location accross platform.\n",
    "\n",
    "# create bar plot of reviews counts for different places\n",
    "attraction_count = review_all['attraction'].value_counts()\n",
    "fig = px.bar(attraction_count.head(10))\n",
    "fig.update_xaxes(title='Place Name')\n",
    "fig.update_yaxes(title='# of Reviews')\n",
    "fig.update_layout(title='# of Reviews for Places (Top 10)')\n",
    "fig.show()\n",
    "\n",
    "########################   Date Wise Analysis ########################   \n",
    "We first converted *datecolumn* to two columns month and year, and we analyze how many reviews are made in the last year from Mar 2022 to Feb 2023. We didn't analyze every year because covid hitted in between, and it may not represent to overall trend.\n",
    "\n",
    "# Convert datecolumns to month and year\n",
    "review_all['month'] = review_all['datecolumn'].dt.month\n",
    "review_all['year'] = review_all['datecolumn'].dt.year\n",
    "\n",
    "# Create barplot for # reviews in a year\n",
    "year_count = review_all['year'].value_counts()\n",
    "fig = px.bar(year_count)\n",
    "fig.update_xaxes(title='Year')\n",
    "fig.update_yaxes(title='# of Reviews')\n",
    "fig.update_layout(title='# of Reviews by Year')\n",
    "fig.show()\n",
    "\n",
    "# Create bar plot for reviews between mar 2022 to feb 2023\n",
    "year2022 = review_all.loc[(review_all['datecolumn']>'2022-2-28') & (review_all['datecolumn']<'2023-3-1')]\n",
    "month2022_count = year2022['month'].value_counts()\n",
    "fig = px.bar(month2022_count)\n",
    "fig.update_xaxes(title='Month')\n",
    "fig.update_yaxes(title='# of Reviews')\n",
    "fig.update_layout(title='# of Reviews by Month from Mar 2022 to Feb 2023')\n",
    "fig.show()\n",
    "\n",
    "The result shows that lots of those reviews are from 2019 and 2022. Since we want to based on only the past year, we plot the bar plot for month from Jan to Dec. The results shows that there are more proportion of reviews are left in between Jun-Sep 2022,\n",
    "One explanation might be that its summer vacation at that period of time, lots of family might travel with their children. Another explanation could be related to the decline in covid worldwide."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
